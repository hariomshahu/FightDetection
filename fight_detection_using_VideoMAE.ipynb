{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPQ9swTqeFxopFG1hify5I3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hariomshahu/FightDetection/blob/VideoMAE_Transformer/fight_detection_using_VideoMAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d-mpwL1uJw6x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3707a52-842d-4ff4-ce3d-f2a6124b640f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "WDQcEPrAKLNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5c44a7-505b-4808-9f45-df0750c01bce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "CE7_IkDyLKOL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/kaggle_api_credentials/kaggle.json\" ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "fCw2cR90KwEV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "aeT_QxraLM5P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d vulamnguyen/rwf2000/"
      ],
      "metadata": {
        "id": "PWtkWV0kM2am",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f0eae5f-6a0f-4b4a-9f51-651ee389ec38"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/vulamnguyen/rwf2000/versions/\n",
            "License(s): unknown\n",
            "Downloading rwf2000.zip to /content\n",
            "100% 11.4G/11.5G [01:14<00:00, 155MB/s]\n",
            "100% 11.5G/11.5G [01:14<00:00, 165MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_zip = \"rwf2000.zip\"\n",
        "\n",
        "destination_folder = \"/content/dataset\"\n",
        "\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "!unzip -q $dataset_zip -d $destination_folder"
      ],
      "metadata": {
        "id": "v12hAWMPOuPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28da4188-83ba-4137-deff-06bc07c948b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/1060314╤ДтХХ╨╜╤Е╨│╨▓╤Е╨┤╨╣╤Ж╨й╨п╤Й╨Ц╨╗╤Й╨й╨▓╤Ж╨Р╨╡╤И╨╕тХС╤Е╨╛╨┤╤Ж╨ктФд╤Е╨Ъ╨л╤ДтХС╨Ы╤ДтХЧтХв╤ПтХЭ╨Ш╤Е╨Э╨о╤Й╨Ч╨б╤ЕтФВтЦС╤ПтХЭ╨Щ_17.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤ДтХХ╨┤╤Е╨╡тФВ╤Е╨╜╨а╤ЕтХС╨з╤Й╨Ч╨Ь╤Ж╨Щ╨г╤Ж╨отХв╤ПтХЭ╨Ь╤Е╨ЭтФд╤ЕтХЭ╨е╤Е╨Я╨б╤Ж╨етЦС╤Е╨а╨Э╤З╨дтХЦ╤Е╨╜╨а╤Е╨ЧтХС╤Ж╨Щ╨Ы╤ПтХЭ╨Ь╤Ж╨и╨┐╤ДтХЧ╨Р╤ДтХг╨Ш╤Е╨Ю╨п╤Е╨л╨░╤ПтХЭ╨п╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Е╨Х╨╕╤З╨╕╨Ы_urlgot_220.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤ДтХХ╨┤╤Е╨╡тФВ╤Е╨╜╨а╤ЕтХС╨з╤Й╨Ч╨Ь╤Ж╨Щ╨г╤Ж╨отХв╤ПтХЭ╨Ь╤Е╨ЭтФд╤ЕтХЭ╨е╤Е╨Я╨б╤Ж╨етЦС╤Е╨а╨Э╤З╨дтХЦ╤Е╨╜╨а╤Е╨ЧтХС╤Ж╨Щ╨Ы╤ПтХЭ╨Ь╤Ж╨и╨┐╤ДтХЧ╨Р╤ДтХг╨Ш╤Е╨Ю╨п╤Е╨л╨░╤ПтХЭ╨п╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Е╨Х╨╕╤З╨╕╨Ы_urlgot_221.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨а╨Ь╤И╨▒╨Ь╤И╨Р╨С╤Ж╨нтФР╤Е╨Я╨╗╤Ж╨н╨╡╤ЕтХХ╨╛╤ЖтФдтХЫ╤Ж╨Щ╨г╤Ж╨отХв╤ПтХЭ╨Ь╤ДтХХ╨Ы╤ДтХХ╨Р╤З╨╖╨в╤Ж╨м╨Щ╤ДтХСтХС╤И╨╖╨С╤Ж╨╜тХЧ╤З╨╡╨о╤ДтХС╨Ц╤ПтХЭ╨Ь╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Ж╨У╨╕╤З╨У╨Ш╤З╨дтХЧ╤Й╨н╨▓╤ПтХЭ╨С_urlgot_222.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨а╨Ь╤И╨▒╨Ь╤И╨Р╨С╤Ж╨нтФР╤Е╨Я╨╗╤Ж╨н╨╡╤ЕтХХ╨╛╤ЖтФдтХЫ╤Ж╨Щ╨г╤Ж╨отХв╤ПтХЭ╨Ь╤ДтХХ╨Ы╤ДтХХ╨Р╤З╨╖╨в╤Ж╨м╨Щ╤ДтХСтХС╤И╨╖╨С╤Ж╨╜тХЧ╤З╨╡╨о╤ДтХС╨Ц╤ПтХЭ╨Ь╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Ж╨У╨╕╤З╨У╨Ш╤З╨дтХЧ╤Й╨н╨▓╤ПтХЭ╨С_urlgot_223.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨а╨Ь╤И╨▒╨Ь╤И╨Р╨С╤Ж╨нтФР╤Е╨Я╨╗╤Ж╨н╨╡╤ЕтХХ╨╛╤ЖтФдтХЫ╤Ж╨Щ╨г╤Ж╨отХв╤ПтХЭ╨Ь╤ДтХХ╨Ы╤ДтХХ╨Р╤З╨╖╨в╤Ж╨м╨Щ╤ДтХСтХС╤И╨╖╨С╤Ж╨╜тХЧ╤З╨╡╨о╤ДтХС╨Ц╤ПтХЭ╨Ь╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Ж╨У╨╕╤З╨У╨Ш╤З╨дтХЧ╤Й╨н╨▓╤ПтХЭ╨С_urlgot_224.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨а╨Ю╤Е╨Ю╨╕╤Й╨Ч╨Ь╤Й╨н╨▓╤ДтХХ╨Р╤И╨╕╨Р╤ДтХХ╨Э╤Е╨а╨Ш╤ЕтЦСтЦТ╤ЕтХЭ╨Р╤Ж╨Щ╨г╤ПтХЭ╨Ь╤Ж╨Ы╨Щ╤Ж╨отХв╤Е╨Я╨и╤Ж╨Щ╨г╤Ж╨отХв╤ПтХЭ╨Ь╤З╨ЮтЦС╤Е╨мтХС╤ДтХХ╨Р╤З╨Щ╨Ч╤ЖтХЦтХЦ╤ДтХгтЦТ╤ПтХЭ╨Ь╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Е╨Х╨╕╤З╨╕╨Ы_urlgot_233.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨а╨Ю╤Е╨Ю╨╕╤Й╨Ч╨Ь╤Й╨н╨▓╤ДтХХ╨Р╤И╨╕╨Р╤ДтХХ╨Э╤Е╨а╨Ш╤ЕтЦСтЦТ╤ЕтХЭ╨Р╤Ж╨Щ╨г╤ПтХЭ╨Ь╤Ж╨Ы╨Щ╤Ж╨отХв╤Е╨Я╨и╤Ж╨Щ╨г╤Ж╨отХв╤ПтХЭ╨Ь╤З╨ЮтЦС╤Е╨мтХС╤ДтХХ╨Р╤З╨Щ╨Ч╤ЖтХЦтХЦ╤ДтХгтЦТ╤ПтХЭ╨Ь╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Е╨Х╨╕╤З╨╕╨Ы_urlgot_235.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨а╨Ю╤Е╨Ю╨╕╤Й╨Ч╨Ь╤Й╨н╨▓╤ДтХХ╨Р╤И╨╕╨Р╤ДтХХ╨Э╤Е╨а╨Ш╤ЕтЦСтЦТ╤ЕтХЭ╨Р╤Ж╨Щ╨г╤ПтХЭ╨Ь╤Ж╨Ы╨Щ╤Ж╨отХв╤Е╨Я╨и╤Ж╨Щ╨г╤Ж╨отХв╤ПтХЭ╨Ь╤З╨ЮтЦС╤Е╨мтХС╤ДтХХ╨Р╤З╨Щ╨Ч╤ЖтХЦтХЦ╤ДтХгтЦТ╤ПтХЭ╨Ь╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Е╨Х╨╕╤З╨╕╨Ы_urlgot_236.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨а╨Ю╤Е╨Ю╨╕╤Й╨Ч╨Ь╤Й╨н╨▓╤ДтХХ╨Р╤И╨╕╨Р╤ДтХХ╨Э╤Е╨а╨Ш╤ЕтЦСтЦТ╤ЕтХЭ╨Р╤Ж╨Щ╨г╤ПтХЭ╨Ь╤Ж╨Ы╨Щ╤Ж╨отХв╤Е╨Я╨и╤Ж╨Щ╨г╤Ж╨отХв╤ПтХЭ╨Ь╤З╨ЮтЦС╤Е╨мтХС╤ДтХХ╨Р╤З╨Щ╨Ч╤ЖтХЦтХЦ╤ДтХгтЦТ╤ПтХЭ╨Ь╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Е╨Х╨╕╤З╨╕╨Ы_urlgot_237.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨а╨Ю╤Е╨Ю╨╕╤Й╨Ч╨Ь╤Й╨н╨▓╤ДтХХ╨Р╤И╨╕╨Р╤ДтХХ╨Э╤Е╨а╨Ш╤ЕтЦСтЦТ╤ЕтХЭ╨Р╤Ж╨Щ╨г╤ПтХЭ╨Ь╤Ж╨Ы╨Щ╤Ж╨отХв╤Е╨Я╨и╤Ж╨Щ╨г╤Ж╨отХв╤ПтХЭ╨Ь╤З╨ЮтЦС╤Е╨мтХС╤ДтХХ╨Р╤З╨Щ╨Ч╤ЖтХЦтХЦ╤ДтХгтЦТ╤ПтХЭ╨Ь╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Е╨Х╨╕╤З╨╕╨Ы_urlgot_238.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨а╨Ю╤Е╨Ю╨╕╤Й╨Ч╨Ь╤Й╨н╨▓╤ДтХХ╨Р╤И╨╕╨Р╤ДтХХ╨Э╤Е╨а╨Ш╤ЕтЦСтЦТ╤ЕтХЭ╨Р╤Ж╨Щ╨г╤ПтХЭ╨Ь╤Ж╨Ы╨Щ╤Ж╨отХв╤Е╨Я╨и╤Ж╨Щ╨г╤Ж╨отХв╤ПтХЭ╨Ь╤З╨ЮтЦС╤Е╨мтХС╤ДтХХ╨Р╤З╨Щ╨Ч╤ЖтХЦтХЦ╤ДтХгтЦТ╤ПтХЭ╨Ь╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Е╨Х╨╕╤З╨╕╨Ы_urlgot_242.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨┤╨╖╤Й╨й╨Ц╤З╨а╨Ц╤Е╨Я╨б╤ЕтХС╨з╤Е╨Я╨б╤З╨д╨п╤З╨░╨Э╤ДтХСтХС╤ДтХС╨Ы╤ДтХЧтХв╤ПтХЭ╨Ь╤ДтХХ╨Ы╤Ж╨Щ╨Ы╤З╨м╨п╤З╨Ы╨░╤ПтХЭ╨С_urlgot_121.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨┤╨╖╤Й╨й╨Ц╤З╨а╨Ц╤Е╨Я╨б╤ЕтХС╨з╤Е╨Я╨б╤З╨д╨п╤З╨░╨Э╤ДтХСтХС╤ДтХС╨Ы╤ДтХЧтХв╤ПтХЭ╨Ь╤ДтХХ╨Ы╤Ж╨Щ╨Ы╤З╨м╨п╤З╨Ы╨░╤ПтХЭ╨С_urlgot_122.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨┤╨╖╤Й╨й╨Ц╤З╨а╨Ц╤Е╨Я╨б╤ЕтХС╨з╤Е╨Я╨б╤З╨д╨п╤З╨░╨Э╤ДтХСтХС╤ДтХС╨Ы╤ДтХЧтХв╤ПтХЭ╨Ь╤ДтХХ╨Ы╤Ж╨Щ╨Ы╤З╨м╨п╤З╨Ы╨░╤ПтХЭ╨С_urlgot_123.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨┤╨╖╤Й╨й╨Ц╤З╨а╨Ц╤Е╨Я╨б╤ЕтХС╨з╤Е╨Я╨б╤З╨д╨п╤З╨░╨Э╤ДтХСтХС╤ДтХС╨Ы╤ДтХЧтХв╤ПтХЭ╨Ь╤ДтХХ╨Ы╤Ж╨Щ╨Ы╤З╨м╨п╤З╨Ы╨░╤ПтХЭ╨С_urlgot_127.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤Е╨╢╨Т╤Ж╨о╨м╤ДтХХ╨Э╤Ж╨и╨┐╤З╨л╨б╤Ж╨Ю╨╖,╤ИтЦС╨С╤ДтХЭ╨к╤З╨лтХХ╤ДтФР╨▒╤ЕтЦС╨Я╤ДтХЭ╨й╤ДтХХтХС╤ДтХС╨Ц╤Ж╨Щ╨г╤Ж╨отХв╤З╨лтФд╤Ж╨Ю╨╡╤ДтХЧ╨Ю╤ДтХС╨Ь╤Ж╨╡тХЭ╤ИтХЦтФВ╤ДтХХ╨Ы╤Е╨ЮтХЧ_urlgot_254.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤ЕтХгтФР╤ДтХХ╨м╤З╨м╨С╤ЖтЦТ╨е╤Е╨┤тФд╤ЕтХХ╨Т╤ЖтХЬ╨╛╤Й╨итФВ╤Е╨ЬтХС╤Й╨г╨м╤З╨л╨Т╤Й╨е╨Ч╤ЖтЦУтФВ╤Й╨й╨Ч╤Ж╨н╨б╤Ж╨ктФд╤Е╨Ъ╨л╤ДтХС╨Ы╤ДтХЧтХв╤З╨л╨б╤Ж╨Ю╨╖╤И╨╖╨Ц╤Й╨▓╨б2_urlgot_138.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤ЕтХгтФР╤ДтХХ╨м╤З╨м╨С╤ЖтЦТ╨е╤Е╨┤тФд╤ЕтХХ╨Т╤ЖтХЬ╨╛╤Й╨итФВ╤Е╨ЬтХС╤Й╨г╨м╤З╨л╨Т╤Й╨е╨Ч╤ЖтЦУтФВ╤Й╨й╨Ч╤Ж╨н╨б╤Ж╨ктФд╤Е╨Ъ╨л╤ДтХС╨Ы╤ДтХЧтХв╤З╨л╨б╤Ж╨Ю╨╖╤И╨╖╨Ц╤Й╨▓╨б2_urlgot_139.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤ЕтХгтФР╤ДтХХ╨м╤З╨м╨С╤ЖтЦТ╨е╤Е╨┤тФд╤ЕтХХ╨Т╤ЖтХЬ╨╛╤Й╨итФВ╤Е╨ЬтХС╤Й╨г╨м╤З╨л╨Т╤Й╨е╨Ч╤ЖтЦУтФВ╤Й╨й╨Ч╤Ж╨н╨б╤Ж╨ктФд╤Е╨Ъ╨л╤ДтХС╨Ы╤ДтХЧтХв╤З╨л╨б╤Ж╨Ю╨╖╤И╨╖╨Ц╤Й╨▓╨б2_urlgot_140.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤ЕтХгтФР╤ДтХХ╨м╤З╨м╨С╤ЖтЦТ╨е╤Е╨┤тФд╤ЕтХХ╨Т╤ЖтХЬ╨╛╤Й╨итФВ╤Е╨ЬтХС╤Й╨г╨м╤З╨л╨Т╤Й╨е╨Ч╤ЖтЦУтФВ╤Й╨й╨Ч╤Ж╨н╨б╤Ж╨ктФд╤Е╨Ъ╨л╤ДтХС╨Ы╤ДтХЧтХв╤З╨л╨б╤Ж╨Ю╨╖╤И╨╖╨Ц╤Й╨▓╨б2_urlgot_141.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Й╨┤╨а╤Е╨Ю╨Х╤ДтХХ╨Р╤ЗтХЫ╨┤╤ЕтЦС╨Я╤ДтХЭ╨й╤Ж╨Щ╨г╤Ж╨отХв╤Ж╨ж╨з╤Ж╨╛тФд ╤И╨Р╨С╤Ж╨нтФР╤З╨о╨╝╤Й╨зтФд╤Е╨Я╨б╤Й╨│╨й╤ДтХС╨Ц_urlgot_267.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Й╨┤╨а╤Е╨Ю╨Х╤ДтХХ╨Р╤ЗтХЫ╨┤╤ЕтЦС╨Я╤ДтХЭ╨й╤Ж╨Щ╨г╤Ж╨отХв╤Ж╨ж╨з╤Ж╨╛тФд ╤И╨Р╨С╤Ж╨нтФР╤З╨о╨╝╤Й╨зтФд╤Е╨Я╨б╤Й╨│╨й╤ДтХС╨Ц_urlgot_268.avi\n",
            "        File name too long\n",
            "error:  cannot create /content/dataset/RWF-2000/train/Fight/╤З╨л╨б╤Ж╨Ю╨╖╤Ж╨Ы╨Э╤ДтХХ╨Ы╤Й╨┤╨а╤Е╨Ю╨Х╤ДтХХ╨Р╤ЗтХЫ╨┤╤ЕтЦС╨Я╤ДтХЭ╨й╤Ж╨Щ╨г╤Ж╨отХв╤Ж╨ж╨з╤Ж╨╛тФд ╤И╨Р╨С╤Ж╨нтФР╤З╨о╨╝╤Й╨зтФд╤Е╨Я╨б╤Й╨│╨й╤ДтХС╨Ц_urlgot_279.avi\n",
            "        File name too long\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetV2B0\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
      ],
      "metadata": {
        "id": "Fx_U674s_kPu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import VideoMAEImageProcessor, VideoMAEForVideoClassification\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, video_paths, labels, image_processor, num_frames=16):\n",
        "        self.video_paths = video_paths\n",
        "        self.labels = labels\n",
        "        self.image_processor = image_processor\n",
        "        self.num_frames = num_frames\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video_path = self.video_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Load and preprocess video frames\n",
        "        frames = self._load_video(video_path)\n",
        "\n",
        "        # Ensure we have exactly num_frames\n",
        "        if len(frames) < self.num_frames:\n",
        "            # If we don't have enough frames, duplicate the last frame\n",
        "            last_frame = frames[-1] if frames else Image.fromarray(np.zeros((224, 224, 3), dtype=np.uint8))\n",
        "            while len(frames) < self.num_frames:\n",
        "                frames.append(last_frame)\n",
        "        elif len(frames) > self.num_frames:\n",
        "            # If we have too many frames, sample evenly\n",
        "            indices = np.linspace(0, len(frames)-1, self.num_frames, dtype=int)\n",
        "            frames = [frames[i] for i in indices]\n",
        "\n",
        "        # Process frames\n",
        "        processed = self.image_processor(frames, return_tensors=\"pt\")\n",
        "\n",
        "        return {\n",
        "            'pixel_values': processed['pixel_values'][0],\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def _load_video(self, video_path):\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frames = []\n",
        "\n",
        "        try:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                # Convert to RGB\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # Resize to 224x224 (VideoMAE default size)\n",
        "                frame = cv2.resize(frame, (224, 224))\n",
        "\n",
        "                # Convert to PIL Image\n",
        "                frame = Image.fromarray(frame)\n",
        "                frames.append(frame)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading video {video_path}: {str(e)}\")\n",
        "\n",
        "        finally:\n",
        "            cap.release()\n",
        "\n",
        "        # If no frames were read, create a dummy frame\n",
        "        if not frames:\n",
        "            dummy_frame = Image.fromarray(np.zeros((224, 224, 3), dtype=np.uint8))\n",
        "            frames = [dummy_frame] * self.num_frames\n",
        "\n",
        "        return frames\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    # Get paths for train set\n",
        "    train_dir = os.path.join(data_dir, 'train')\n",
        "    train_fight_dir = os.path.join(train_dir, 'Fight')\n",
        "    train_nonfight_dir = os.path.join(train_dir, 'NonFight')\n",
        "\n",
        "    train_fight_videos = [os.path.join(train_fight_dir, f) for f in os.listdir(train_fight_dir) if f.endswith('.avi')]\n",
        "    train_nonfight_videos = [os.path.join(train_nonfight_dir, f) for f in os.listdir(train_nonfight_dir) if f.endswith('.avi')]\n",
        "\n",
        "    train_paths = train_fight_videos + train_nonfight_videos\n",
        "    train_labels = [1] * len(train_fight_videos) + [0] * len(train_nonfight_videos)\n",
        "\n",
        "    # Get paths for validation set\n",
        "    val_dir = os.path.join(data_dir, 'val')\n",
        "    val_fight_dir = os.path.join(val_dir, 'Fight')\n",
        "    val_nonfight_dir = os.path.join(val_dir, 'NonFight')\n",
        "\n",
        "    val_fight_videos = [os.path.join(val_fight_dir, f) for f in os.listdir(val_fight_dir) if f.endswith('.avi')]\n",
        "    val_nonfight_videos = [os.path.join(val_nonfight_dir, f) for f in os.listdir(val_nonfight_dir) if f.endswith('.avi')]\n",
        "\n",
        "    val_paths = val_fight_videos + val_nonfight_videos\n",
        "    val_labels = [1] * len(val_fight_videos) + [0] * len(val_nonfight_videos)\n",
        "\n",
        "    return train_paths, train_labels, val_paths, val_labels\n",
        "\n",
        "def train_model(train_dataset, val_dataset, num_epochs=10, batch_size=2):  # Reduced batch size\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=2,\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    model = VideoMAEForVideoClassification.from_pretrained(\n",
        "        \"MCG-NJU/videomae-base-finetuned-kinetics\",\n",
        "        num_labels=2,\n",
        "        label2id={\"NonFight\": 0, \"Fight\": 1},\n",
        "        id2label={0: \"NonFight\", 1: \"Fight\"},\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "\n",
        "    # Move model to GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Initialize optimizer\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # Training loop\n",
        "    best_val_accuracy = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in train_loader:\n",
        "            pixel_values = batch['pixel_values'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        print(f\"Average training loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                pixel_values = batch['pixel_values'].to(device)\n",
        "                labels = batch['label'].to(device)\n",
        "\n",
        "                outputs = model(pixel_values=pixel_values)\n",
        "                predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "                val_preds.extend(predictions.cpu().numpy())\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate metrics\n",
        "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(val_labels, val_preds, average='binary')\n",
        "\n",
        "        print(f\"Validation Metrics:\")\n",
        "        print(f\"Accuracy: {val_accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            model.save_pretrained(\"best_model\")\n",
        "            print(f\"New best model saved with validation accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    # Set random seeds\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Print GPU information\n",
        "    print(\"GPU Available:\", torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "        print(\"Memory:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")\n",
        "\n",
        "    # Initialize the image processor\n",
        "    image_processor = VideoMAEImageProcessor.from_pretrained(\"MCG-NJU/videomae-base-finetuned-kinetics\")\n",
        "    print(\"\\nImage Processor Config:\", image_processor.image_mean, image_processor.image_std)\n",
        "\n",
        "    # Prepare data\n",
        "    print(\"\\nPreparing datasets...\")\n",
        "    data_dir = '/content/dataset/RWF-2000'\n",
        "    train_paths, train_labels, val_paths, val_labels = prepare_data(data_dir)\n",
        "    print(f\"Found {len(train_paths)} training videos and {len(val_paths)} validation videos\")\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = VideoDataset(train_paths, train_labels, image_processor)\n",
        "    val_dataset = VideoDataset(val_paths, val_labels, image_processor)\n",
        "    print(\"Datasets created successfully\")\n",
        "\n",
        "    # Train model\n",
        "    print(\"\\nStarting training...\")\n",
        "    model = train_model(train_dataset, val_dataset)\n",
        "    print(\"Training completed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFqdEvNtMUXB",
        "outputId": "b91a50f7-e9ba-4981-f606-73d6d512476c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n",
            "GPU: NVIDIA A100-SXM4-40GB\n",
            "Memory: 42.481811456 GB\n",
            "\n",
            "Image Processor Config: [0.485, 0.456, 0.406] [0.229, 0.224, 0.225]\n",
            "\n",
            "Preparing datasets...\n",
            "Found 1576 training videos and 400 validation videos\n",
            "Datasets created successfully\n",
            "\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base-finetuned-kinetics and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([400]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([400, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "Average training loss: 0.6127\n",
            "Validation Metrics:\n",
            "Accuracy: 0.7600\n",
            "Precision: 0.7342\n",
            "Recall: 0.8150\n",
            "F1-score: 0.7725\n",
            "New best model saved with validation accuracy: 0.7600\n",
            "\n",
            "Epoch 2/10\n",
            "Average training loss: 0.5601\n",
            "Validation Metrics:\n",
            "Accuracy: 0.7300\n",
            "Precision: 0.6597\n",
            "Recall: 0.9500\n",
            "F1-score: 0.7787\n",
            "\n",
            "Epoch 3/10\n",
            "Average training loss: 0.5126\n",
            "Validation Metrics:\n",
            "Accuracy: 0.7375\n",
            "Precision: 0.8276\n",
            "Recall: 0.6000\n",
            "F1-score: 0.6957\n",
            "\n",
            "Epoch 4/10\n",
            "Average training loss: 0.4496\n",
            "Validation Metrics:\n",
            "Accuracy: 0.7200\n",
            "Precision: 0.8333\n",
            "Recall: 0.5500\n",
            "F1-score: 0.6627\n",
            "\n",
            "Epoch 5/10\n",
            "Average training loss: 0.4003\n",
            "Validation Metrics:\n",
            "Accuracy: 0.6825\n",
            "Precision: 0.8349\n",
            "Recall: 0.4550\n",
            "F1-score: 0.5890\n",
            "\n",
            "Epoch 6/10\n",
            "Average training loss: 0.3457\n",
            "Validation Metrics:\n",
            "Accuracy: 0.7725\n",
            "Precision: 0.7559\n",
            "Recall: 0.8050\n",
            "F1-score: 0.7797\n",
            "New best model saved with validation accuracy: 0.7725\n",
            "\n",
            "Epoch 7/10\n",
            "Average training loss: 0.2941\n",
            "Validation Metrics:\n",
            "Accuracy: 0.7050\n",
            "Precision: 0.8475\n",
            "Recall: 0.5000\n",
            "F1-score: 0.6289\n",
            "\n",
            "Epoch 8/10\n",
            "Average training loss: 0.2466\n",
            "Validation Metrics:\n",
            "Accuracy: 0.6950\n",
            "Precision: 0.7600\n",
            "Recall: 0.5700\n",
            "F1-score: 0.6514\n",
            "\n",
            "Epoch 9/10\n",
            "Average training loss: 0.2031\n",
            "Validation Metrics:\n",
            "Accuracy: 0.7075\n",
            "Precision: 0.7485\n",
            "Recall: 0.6250\n",
            "F1-score: 0.6812\n",
            "\n",
            "Epoch 10/10\n",
            "Average training loss: 0.2121\n",
            "Validation Metrics:\n",
            "Accuracy: 0.7525\n",
            "Precision: 0.7416\n",
            "Recall: 0.7750\n",
            "F1-score: 0.7579\n",
            "Training completed!\n"
          ]
        }
      ]
    }
  ]
}